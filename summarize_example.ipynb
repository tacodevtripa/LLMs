{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Primera interaccion con un LLM desde VSCode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Llamada de prueba a nuestro modelo local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "model.invoke(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## Comenzando nuestro primer proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e793b2-6775-426a-a139-4848291d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers) # obtener el sitio web\n",
    "        soup = BeautifulSoup(response.content, 'html.parser') # formatear como HTML\n",
    "        self.title = soup.title.string if soup.title else \"No title found\" # configurar 'title' en caso de que haya\n",
    "        for irrelevant in soup.find_all(['script', 'style', 'img', 'input']): #eliminar etiquetas irrelevantes para el proyecto\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b6526",
   "metadata": {},
   "source": [
    "# Probando el codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tacodevtripa = Website(\"https://github.com/tacodevtripa\")\n",
    "print(tacodevtripa.title)\n",
    "print(tacodevtripa.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Tipos de Prompts\n",
    "\n",
    "\n",
    "**system prompt** descripcion de la tarea especifica, asi como la manera en que esta debe ser realizada\n",
    "\n",
    "**user prompt** -- Input por parte del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"En esta definicion cada detalle importa, el simple hecho de agregar una instruccion puedes cambiar por completo\n",
    "el formato en el que el LLM genera su respuesta, incluyendo traduccion a otro idioma o formato especifico (JSON, YML, etc)\"\"\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b592a6f",
   "metadata": {},
   "source": [
    "### Funcion para generar el formato deseado del input de usuario, incluyendo las variables para el contenido dinamico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26448ec4-5c00-4204-baec-7df91d11ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompt_for(tacodevtripa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "# Mensajes\n",
    "\n",
    "OpenAI establecio un formato para la manera en que la informacion es procesada por los LLMs, el siguiente ejemplo\n",
    "es la forma mas basica, donde la estructura es una lista `[]` de diccionarios `{key:value}`, o elementos tipo llave:valor\n",
    "\n",
    "Asi es posible para el LLMs diferencias que tipo de prompt esta procesando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Spanish assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed95c5-7001-47de-a36d-1d6673b403ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamada a olama, el resultado es devuelto una vez terminado de procesar por completo\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50576118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El resultado es devuelto 'a trozos', por lo que se puede iterar para mostrarlo en pantalla conforme es recibido\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk, end=\" \") #usamos el parametro de `end=\" \"` para sobreescribir que por defecto `print()` agregue un salto de linea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## Funcion para crear los mensajes con el formato especificado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for_LLM(system_prompt, website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}, #configuracion del system prompt\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)} #configuracion del input de usuario con los datos de la pagina web\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for_LLM(system_prompt, tacodevtripa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "# Funcion para unir todo\n",
    "\n",
    "## Al proveer la URL del sitio web deseado:\n",
    "- Se creara la instancia de dicho sitio web\n",
    "- Por medio de el constructor de dicho metodo se almacena la informacion deseada\n",
    "- Y se devuelve la respuesta del LLM, usando los metodos anteriores para obtener el resultado deseado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    return model.invoke(messages_for_LLM(system_prompt, website))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probando funcion\n",
    "summarize(\"https://github.com/tacodevtripa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo para modificar el formato de la respuesta con la libreria de `Markdown`\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probando funcion\n",
    "display_summary(\"https://github.com/tacodevtripa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Probemos mas sitios web\n",
    "\n",
    "Este proyecto solo funcionara con sitios web muy basicos, puesto que algunos sitios web que usen frameworks como React, al renderizar los elementos conforme interactuas con la pagina, la informacion puede ser no muy precisa\n",
    "\n",
    "E incluso algunos sitios web cuentan con alguna proteccion basica gracias a sus proveedores de DNS, como CloudFrount, y su acceso por medio de estas librerias puede no funcionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://www.thetimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://python.langchain.com/docs/introduction/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c305b8",
   "metadata": {},
   "source": [
    "## Ejemplo Adicional\n",
    "\n",
    "- El `System Prompt` fue definido para crear un ayudante en la creacion de los asuntos para los correos electronicos de acuerdo a su contenido\n",
    "- Por `User Prompt` pasaremos el contenido completo de un correo electronico inventado, la forma en que esta informacion llegue ya la dejo a su imaginacion\n",
    "- Notese como se especifica en el System Prompt que solo provea el 'asunto' para dicho email, para poder utilizar dicho valor y guardarlo en una variable, esto puede o no funcionar dependiendo de la 'fuerza' de cada LLM, pero por lo general siempre funciona, cosa que incluso puede ser cambiada para pedir varias opciones en una sola respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Analyze the email content and suggest a clear, concise, and effective subject line. Your task is to:\n",
    "\n",
    "1. Read and understand the entire email content.\n",
    "2. Identify the main topic or purpose of the email.\n",
    "3. Determine the tone and language used in the email (e.g., formal, informal, promotional).\n",
    "4. Consider the recipient's context and potential emotional resonance.\n",
    "\n",
    "Create a subject line that accurately reflects the content of the email and is likely to capture the attention of\n",
    "the recipient.\n",
    "\n",
    "Provide nothing but the subject line, so the value can be stored in a variable, and provide 3 options\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Dear Tacodevtripa,\n",
    "\n",
    "We're excited to announce the launch of our new product, \"EcoCycle\" - a revolutionary recycling system designed to\n",
    "help households and businesses reduce their waste output.\n",
    "\n",
    "As one of our valued partners, we're offering you an exclusive 10% discount on your first purchase. Simply use the\n",
    "code ECOCYCLE10 at checkout to redeem your discount.\n",
    "\n",
    "Our team has worked tirelessly to develop EcoCycle, and we're confident it will make a significant impact in\n",
    "reducing waste and promoting sustainability.\n",
    "\n",
    "To learn more about EcoCycle and how it can benefit your organization, please click on the link below:\n",
    "\n",
    "\n",
    "Best regards,\n",
    "EcoCycle Team\n",
    "\"\"\"\n",
    "\n",
    "def messages_for_email_agent(system_prompt, content):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": content}\n",
    "    ]\n",
    "messages = messages_for_email_agent(system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180840b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
