{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "**Beneficios**\n",
    "1. Sin costo por uso de API, es totalmente local\n",
    "2. Los datos nunca dejan tu computadora\n",
    "\n",
    "**Desventajas**\n",
    "1. Mucha menos potencia que cualquier modelo de paga como la API de OpenAI o plataformas similares\n",
    "\n",
    "## Recapitulacion de la instalacion\n",
    "\n",
    "Solo visita [ollama.com](https://ollama.com) e instala su software\n",
    "\n",
    "Cuando la instalacion termina, verifica que Ollama este ejecutandose visitando\n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "Si obtienes el mensaje `Ollama is running`, todo listo\n",
    "\n",
    "En caso de que no, busca la aplicacion de Ollama y abrela de nuevo, o utiliza el comando `ollama serve` desde alguna terminal\n",
    "\n",
    "Para instalar el modelo que menos requerimiento de hardware tiene, ejecuta el siguiente comando, si ya lo tienes instalado omite este paso\n",
    "`ollama run qwen2.5-coder:0.5b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"qwen2.5-coder:0.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format as OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"que es Ollama?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama es un modelo de IA diseñado para responder preguntas y proporcionar información en español. Es una aplicación web que se utiliza principalmente para generar contenido en la web, pero también puede ser usada como un servicio de IA personalizado para proporcionar información a los usuarios.\n"
     ]
    }
   ],
   "source": [
    "#Peticion a Ollama\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Paquete oficial de Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama es una inteligencia artificial que tiene los conocimientos de un lenguaje natural, se basa en el aprendizaje supervisado por la red neuronal, y utiliza funciones para crear texto y realizar tareas.\n",
      "\n",
      "Ollama también ofrece una gran cantidad de servicios para mejorar su performance, como:\n",
      "\n",
      "1. Generación de texto\n",
      "2. Análisis de texto\n",
      "3. Recogida de datos\n",
      "4. Comunicación digital\n",
      "5. Entrenamiento y mantenimiento\n",
      "\n",
      "Para obtener más información sobre Ollama, puedes buscarla en el sitio web oficial de IBM o en la comunidad de IA.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternativa de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama es un algoritmo de IA que se usa para generar texto a partir de texto proporcionado como input. Su objetivo principal es mantener la conciencia y la precisión en las respuestas, lo cual puede ser útil para responder preguntas con confianza y eficiencia.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-tacodevtripa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
